{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "word_level_category_file = 'cnews_data/word-level/cnews.category.txt'\n",
    "word_level_train_file = 'cnews_data/word-level/cnews.train.txt'\n",
    "word_level_val_file = 'cnews_data/word-level/cnews.val.txt'\n",
    "word_level_test_file  = 'cnews_data/word-level/cnews.test.txt'\n",
    "word_level_vocab_file = 'cnews_data/word-level/cnews.vocab.txt'\n",
    "\n",
    "word_level_feature_folder = 'cnews_data/word-level-feature/'\n",
    "word_level_train_feature_file = 'cnews_data/word-level-feature/cnews.train.txt'\n",
    "word_level_val_feature_file = 'cnews_data/word-level-feature/cnews.val.txt'\n",
    "word_level_test_feature_file  = 'cnews_data/word-level-feature/cnews.test.txt'\n",
    "\n",
    "if not os.path.exists(word_level_feature_folder):\n",
    "    os.mkdir(word_level_feature_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "class Category:\n",
    "    def __init__(self, category_file):\n",
    "        self._category_to_id = {}\n",
    "        with open(category_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            category, idx = line.strip('\\r\\n').split('\\t')\n",
    "            category = category.decode('utf-8')\n",
    "            idx = int(idx)\n",
    "            self._category_to_id[category] = idx\n",
    "    \n",
    "    def category_to_id(self, category):\n",
    "        return self._category_to_id[category]\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self._category_to_id)\n",
    "        \n",
    "category_vocab = Category(word_level_category_file)\n",
    "print category_vocab.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10353\n"
     ]
    }
   ],
   "source": [
    "def generate_feature_dict(train_file, feature_threshold=10):\n",
    "    feature_dict = {}\n",
    "    with open(train_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        label, content = line.decode('utf-8').strip('\\r\\n').split('\\t')\n",
    "        for word in content.split(' '):\n",
    "            if not word in feature_dict:\n",
    "                feature_dict.setdefault(word, 0)\n",
    "            feature_dict[word] += 1\n",
    "    filtered_feature_dict = {}\n",
    "    for feature_name in feature_dict:\n",
    "        if feature_dict[feature_name] < feature_threshold:\n",
    "            continue\n",
    "        if not feature_name in filtered_feature_dict:\n",
    "            filtered_feature_dict[feature_name] = len(filtered_feature_dict) + 1\n",
    "    return filtered_feature_dict\n",
    "        \n",
    "\n",
    "def generate_feature_line(line, feature_dict, category_vocab):\n",
    "    label, content = line.decode('utf-8').strip('\\r\\n').split('\\t')\n",
    "    label_id = category_vocab.category_to_id(label)\n",
    "    feature_example = {}\n",
    "    for word in content.split(' '):\n",
    "        if not word in feature_dict:\n",
    "            continue\n",
    "        feature_id = feature_dict[word]\n",
    "        feature_example.setdefault(feature_id, 0)\n",
    "        feature_example[feature_id] += 1\n",
    "    feature_line = '%d' % label_id\n",
    "    sorted_feature_example = sorted(feature_example.items(), key=lambda d:d[0])\n",
    "    for item in sorted_feature_example:\n",
    "        feature_line += ' %d:%d' % item\n",
    "    return feature_line\n",
    "\n",
    "def convert_raw_to_feature(raw_file, feature_file, feature_dict, category_vocab):\n",
    "    with open(raw_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(feature_file, 'w') as f:\n",
    "        for line in lines:\n",
    "            feature_line = generate_feature_line(line, feature_dict, category_vocab)\n",
    "            f.write('%s\\n' % feature_line)\n",
    "\n",
    "feature_dict = generate_feature_dict(word_level_train_file, feature_threshold=200)\n",
    "print len(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_raw_to_feature(word_level_train_file, word_level_train_feature_file, feature_dict, category_vocab)\n",
    "convert_raw_to_feature(word_level_val_file, word_level_val_feature_file, feature_dict, category_vocab)\n",
    "convert_raw_to_feature(word_level_test_file, word_level_test_feature_file, feature_dict, category_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Results of word-level feature using SVM model\n",
    "       >20     >100    >200\n",
    "Train  100%    100%    100%\n",
    "Valid  92.46%  92.46%  92.34%\n",
    "Test   94.4%   94.11%  94.15%\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
