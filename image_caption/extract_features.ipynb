{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cPickle\n",
    "import time\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _imread(img_path):\n",
    "    \"\"\"Reads img out from file and return Image object\"\"\"\n",
    "    return Image.open(img_path)\n",
    "\n",
    "def _img_scale_on_short_edge(img, new_size):\n",
    "    width, height = img.size\n",
    "    if width < height:\n",
    "        height = int(height * new_size / width)\n",
    "        width = new_size\n",
    "    else:\n",
    "        width = int(width * new_size / height)\n",
    "        height = new_size\n",
    "    new_img = img.resize((width, height))\n",
    "    return new_img\n",
    "\n",
    "def _center_crop(img):\n",
    "    width, height = img.size\n",
    "    result_size = min(width, height)\n",
    "    x = int((width - result_size) / 2)\n",
    "    y = int((height - result_size) / 2)\n",
    "    crop_box = (x, y, x+result_size, y+result_size)\n",
    "    new_img = img.crop(crop_box)\n",
    "    return new_img\n",
    "\n",
    "def loads_images(image_names, images_dir, image_size):\n",
    "    image_data = []\n",
    "    for image_name in image_names:\n",
    "        logging.info(\"load image %s\" % (image_name))\n",
    "        img = _imread(os.path.join(images_dir, image_name))\n",
    "        img = _img_scale_on_short_edge(img, image_size)\n",
    "        img = _center_crop(img)\n",
    "        img_np = np.asarray(img, dtype=np.float32)\n",
    "        img_np = img_np / 127.5 - 1\n",
    "        image_data.append(img_np)\n",
    "    image_data = np.asarray(image_data)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_token_file(token_file):\n",
    "    image_name_to_tokens = {}\n",
    "    with open(token_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        image_id, description = line.strip('\\r\\n').split('\\t')\n",
    "        image_name, _ = image_id.split('#')\n",
    "        image_name_to_tokens.setdefault(image_name, [])\n",
    "        image_name_to_tokens[image_name].append(description)\n",
    "    return image_name_to_tokens\n",
    "  \n",
    "def convert_token_to_id(image_name_to_tokens, vocab):\n",
    "    image_name_to_token_ids = {}\n",
    "    for image_name in image_name_to_tokens:\n",
    "        image_name_to_token_ids.setdefault(image_name, [])\n",
    "        descriptions = image_name_to_tokens[image_name]\n",
    "        for description in descriptions:\n",
    "            token_ids = vocab.encode(description)\n",
    "            image_name_to_token_ids[image_name].append(token_ids)\n",
    "    return image_name_to_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor(model_name, checkpoint_path):\n",
    "    # https://github.com/tensorflow/models/blob/master/research/slim/nets/nets_factory.py\n",
    "    # https://github.com/tensorflow/models/tree/master/research\n",
    "    network_fn = nets_factory.get_network_fn(model_name, num_classes=0, is_training=False)\n",
    "    image_size = network_fn.default_image_size\n",
    "    images_placeholder = tf.placeholder(tf.float32, [None, image_size, image_size, 3])\n",
    "    logits, endpoints = network_fn(images_placeholder)\n",
    "    variables_to_restore = slim.get_variables_to_restore()\n",
    "    restore_fn = slim.assign_from_checkpoint_fn(checkpoint_path, variables_to_restore)\n",
    "    return images_placeholder, logits, restore_fn, image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'inception_v4'\n",
    "checkpoint_path = 'checkpoint_inception_v4/inception_v4.ckpt'\n",
    "images_dir = 'flickr30k_images/'\n",
    "token_file = 'results_20130124.token'\n",
    "output_dir = 'features2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_placeholder, logits, restore_fn, image_size = build_feature_extractor(\n",
    "      model_name, checkpoint_path)\n",
    "\n",
    "image_name_to_tokens = parse_token_file(token_file)\n",
    "\n",
    "existed_all_image_names = []\n",
    "for image_name in image_name_to_tokens:\n",
    "    if os.path.exists(os.path.join(images_dir, image_name)):\n",
    "        existed_all_image_names.append(image_name)\n",
    "\n",
    "tf.logging.info(\"image_size: %d\" % image_size)\n",
    "tf.logging.info(\"num of all images: %d\" % len(existed_all_image_names))\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "example_in_batch = 100\n",
    "example_in_mini_batch = 10\n",
    "\n",
    "num_batches = len(all_image_names) / example_in_batch\n",
    "if len(all_image_names) % example_in_batch != 0:\n",
    "    num_batches += 1\n",
    "num_mini_batches = example_in_batch / example_in_mini_batch\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "restore_fn(sess)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(num_batches):\n",
    "    image_names = all_image_names[i*example_in_batch: (i+1)*example_in_batch]\n",
    "    features = []\n",
    "    for j in range(num_mini_batches):\n",
    "        mini_image_names = image_names[\n",
    "            j*example_in_mini_batch: (j+1)*example_in_mini_batch]\n",
    "\n",
    "        mini_image_data = loads_images(mini_image_names, FLAGS.images_dir, image_size)\n",
    "        logits_val = sess.run(logits, \n",
    "                              feed_dict={images_placeholder: mini_image_data})\n",
    "        num_example, num_width, num_height, num_channel = logits_val.shape\n",
    "        assert num_width == 1 and num_height == 1\n",
    "        logits_val = np.reshape(logits_val, (num_example, num_channel))\n",
    "        print(logits_val.shape)\n",
    "        features.append(logits_val)\n",
    "    features = np.vstack(features)\n",
    "    with open(os.path.join(output_dir, \"image_features-%d.pickle\" % i), 'w') as f:\n",
    "        cPickle.dump((image_names, features), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
